{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e04d12",
   "metadata": {},
   "source": [
    "# Data Preparation & Quality Notebook\n",
    "\n",
    "Lean, reproducible preprocessing for the M5 subset used in this capstone. \n",
    "**Scope:** M5 only, CPU-only workflow, no external augmentation. \n",
    "**Objectives:**\n",
    "1. Load panel-level demand data (or build a small synthetic fallback).\n",
    "2. Profile: shape, date range, item counts, missing & zero-demand rates.\n",
    "3. Validate date continuity per item.\n",
    "4. Flag simple outliers via z-score (>3).\n",
    "5. Apply minimal cleaning (non-negative demand, fill NA with 0).\n",
    "6. Persist a compact JSON + Markdown quality report to `artifacts/data/`.\n",
    "\n",
    "This notebook directly supports GHGSat-aligned responsibilities: Data Exploration, Curation, Quality, and Rapid Prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a202eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & paths\n",
    "import pandas as pd, numpy as np, json, math, os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "DATA_PROCESSED = Path('data/processed')\n",
    "PANEL_PATH = DATA_PROCESSED / 'm5_panel_subset.parquet'\n",
    "ARTIFACT_DIR = Path('artifacts/data')\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create synthetic fallback panel (used if processed subset not present).\n",
    "if PANEL_PATH.exists():\n",
    "    panel_df = pd.read_parquet(PANEL_PATH)\n",
    "    source_note = f'Loaded existing panel: {PANEL_PATH}'\n",
    "else:\n",
    "    print('Panel not found -> generating lightweight synthetic fallback (20 items x 200 days).')\n",
    "    items = [f'ITEM_{i:03d}' for i in range(20)]\n",
    "    dates = pd.date_range('2024-01-01', periods=200, freq='D')\n",
    "    rows = []\n",
    "    for item in items:\n",
    "        base = np.random.randint(5, 25)\n",
    "        seasonal = np.sin(np.linspace(0, 12 * math.pi, len(dates))) * np.random.uniform(3, 8)\n",
    "        noise = np.random.randn(len(dates)) * np.random.uniform(0.5, 2.0)\n",
    "        demand = (base + seasonal + noise).clip(min=0).round(2)\n",
    "        for d, val in zip(dates, demand):\n",
    "            rows.append({'item_id': item, 'date': d, 'demand': float(val)})\n",
    "    panel_df = pd.DataFrame(rows)\n",
    "    DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "    panel_df.to_parquet(PANEL_PATH, index=False)\n",
    "    source_note = 'Synthetic fallback (saved to processed path)'\n",
    "panel_df['date'] = pd.to_datetime(panel_df['date'])\n",
    "print(source_note)\n",
    "panel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic profiling summary\n",
    "n_rows = len(panel_df)\n",
    "n_items = panel_df['item_id'].nunique()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
