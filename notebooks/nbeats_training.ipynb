{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74580b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /Users/zak/Repos/E-commerce-Demand-Forecasting\n",
      "Current working directory: /Users/zak/Repos/E-commerce-Demand-Forecasting/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Ensure project root is on sys.path so `import src...` works\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd().resolve()\n",
    "# If running from inside notebooks/ adjust to parent directory containing src\n",
    "if not (root / 'src').exists():\n",
    "    candidate = root.parent\n",
    "    if (candidate / 'src').exists():\n",
    "        root = candidate\n",
    "# Prepend if missing\n",
    "root_str = str(root)\n",
    "if root_str not in sys.path:\n",
    "    sys.path.insert(0, root_str)\n",
    "print('Added to sys.path:', root_str)\n",
    "print('Current working directory:', Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f227672",
   "metadata": {},
   "source": [
    "# N-BEATS Training Notebook\n",
    "\n",
    "Train the minimal N-BEATS implementation on the panel parquet subset.\n",
    "\n",
    "## Objectives\n",
    "1. Load processed panel data (item_id, date, demand).\n",
    "2. Create sliding window dataset (input_length -> forecast_length).\n",
    "3. Train N-BEATS LightningModule for a few epochs.\n",
    "4. Compute validation metrics (MAE, WAPE).\n",
    "5. Save checkpoint + metrics artifacts.\n",
    "\n",
    "If the panel file is missing, a synthetic dataset will be generated so the pipeline can run end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338f002f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0\n",
      "Lightning version: 2.5.5\n",
      "Device: mps\n",
      "Accelerator: mps\n",
      "Backend note: Using Apple Silicon MPS backend\n"
     ]
    }
   ],
   "source": [
    "# Imports and environment checks (single accelerator definition)\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from src.models.nbeats_module import NBeatsModule, NBeatsConfig\n",
    "from src.data.dataset_nbeats import PanelForecastDataset, PanelWindowConfig, split_dataset\n",
    "\n",
    "# Device & accelerator selection (Apple Silicon, CUDA, CPU)\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    accelerator = 'mps'\n",
    "    backend_note = \"Using Apple Silicon MPS backend\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    accelerator = 'gpu'\n",
    "    backend_note = f\"Using CUDA GPU: {torch.cuda.get_device_name(0)}\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    accelerator = 'cpu'\n",
    "    backend_note = \"Falling back to CPU\"\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('Lightning version:', pl.__version__)\n",
    "print('Device:', device)\n",
    "print('Accelerator:', accelerator)\n",
    "print('Backend note:', backend_note)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4eb01be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config -> stacks: 3 blocks/stack: 3 layer_width: 768 batch_size: 512\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters (aggressive compute - batch 512)\n",
    "PANEL_PATH = Path('data/processed/m5_panel_subset.parquet')\n",
    "ARTIFACTS_DIR = Path('artifacts/models')\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INPUT_LENGTH = 28 * 4  # 112 days lookback\n",
    "FORECAST_LENGTH = 30\n",
    "BATCH_SIZE = 512  # increased substantially\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_STACKS = 3\n",
    "BLOCKS_PER_STACK = 3\n",
    "LAYER_WIDTH = 768\n",
    "N_LAYERS = 4\n",
    "DROPOUT = 0.05\n",
    "MAX_ITEMS = 50\n",
    "MAX_WINDOWS_PER_ITEM = 40\n",
    "VAL_FRACTION = 0.1\n",
    "SEED = 42\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "print('Config -> stacks:', NUM_STACKS, 'blocks/stack:', BLOCKS_PER_STACK, 'layer_width:', LAYER_WIDTH, 'batch_size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a9ce519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading panel from data/processed/m5_panel_subset.parquet\n",
      "    item_id       date  demand\n",
      "0  ITEM_000 2024-01-01   11.90\n",
      "1  ITEM_000 2024-01-02   11.30\n",
      "2  ITEM_000 2024-01-03   11.60\n",
      "3  ITEM_000 2024-01-04   18.30\n",
      "4  ITEM_000 2024-01-05   15.64\n",
      "Panel shape: (4000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load or create synthetic panel\n",
    "if PANEL_PATH.exists():\n",
    "    print('Loading panel from', PANEL_PATH)\n",
    "    panel_df = pd.read_parquet(PANEL_PATH)\n",
    "else:\n",
    "    print('Panel not found. Creating synthetic panel for demo...')\n",
    "    # Synthetic: 20 items, 200 days, simple seasonal pattern + noise\n",
    "    import numpy as np\n",
    "    items = [f'ITEM_{i:03d}' for i in range(20)]\n",
    "    dates = pd.date_range('2024-01-01', periods=200, freq='D')\n",
    "    rows = []\n",
    "    for item in items:\n",
    "        base = np.random.randint(5, 25)\n",
    "        seasonal = np.sin(np.linspace(0, 12 * math.pi, len(dates))) * np.random.uniform(3, 8)\n",
    "        noise = np.random.randn(len(dates)) * np.random.uniform(0.5, 2.0)\n",
    "        demand = (base + seasonal + noise).clip(min=0).round(2)\n",
    "        for d, val in zip(dates, demand):\n",
    "            rows.append({'item_id': item, 'date': d, 'demand': float(val)})\n",
    "    panel_df = pd.DataFrame(rows)\n",
    "    PANEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    panel_df.to_parquet(PANEL_PATH, index=False)\n",
    "print(panel_df.head())\n",
    "print('Panel shape:', panel_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "905be5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff date for validation segment: 2024-06-19 00:00:00\n",
      "Train date range: 2024-01-01 00:00:00 -> 2024-06-18 00:00:00 | rows: 3400\n",
      "Val+history date range: 2024-01-30 00:00:00 -> 2024-07-18 00:00:00 | rows: 3420\n",
      "Windows -> train: 580 val: 600\n",
      "Sample shapes -> x: torch.Size([112]) y: torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# Build dataset windows with chronological split\n",
    "# Determine cutoff date for validation based on VAL_FRACTION of unique days\n",
    "unique_dates = sorted(panel_df['date'].unique())\n",
    "val_days = max(FORECAST_LENGTH, int(len(unique_dates) * VAL_FRACTION))\n",
    "# Ensure we have enough history for validation windows\n",
    "val_history_needed = INPUT_LENGTH + FORECAST_LENGTH\n",
    "cutoff_index = len(unique_dates) - val_days\n",
    "cutoff_date = unique_dates[cutoff_index]\n",
    "\n",
    "# Train: all dates strictly before cutoff_date\n",
    "train_df = panel_df[panel_df['date'] < cutoff_date]\n",
    "# Validation: last segment plus required preceding history window\n",
    "val_start_history_date = unique_dates[max(0, cutoff_index - (val_history_needed - 1))]\n",
    "val_df = panel_df[panel_df['date'] >= val_start_history_date]\n",
    "\n",
    "print('Cutoff date for validation segment:', cutoff_date)\n",
    "print('Train date range:', train_df['date'].min(), '->', train_df['date'].max(), '| rows:', len(train_df))\n",
    "print('Val+history date range:', val_df['date'].min(), '->', val_df['date'].max(), '| rows:', len(val_df))\n",
    "\n",
    "# Persist temporary parquet shards (avoids modifying original panel file)\n",
    "train_path = PANEL_PATH.parent / 'm5_panel_subset_train.parquet'\n",
    "val_path = PANEL_PATH.parent / 'm5_panel_subset_val.parquet'\n",
    "train_df.to_parquet(train_path, index=False)\n",
    "val_df.to_parquet(val_path, index=False)\n",
    "\n",
    "cfg_ds = PanelWindowConfig(input_length=INPUT_LENGTH, forecast_length=FORECAST_LENGTH, max_items=MAX_ITEMS, max_windows_per_item=MAX_WINDOWS_PER_ITEM)\n",
    "train_ds = PanelForecastDataset(train_path, cfg_ds)\n",
    "val_ds = PanelForecastDataset(val_path, cfg_ds)\n",
    "print('Windows -> train:', len(train_ds), 'val:', len(val_ds))\n",
    "# Inspect one sample\n",
    "x0, y0 = train_ds[0]\n",
    "print('Sample shapes -> x:', x0.shape, 'y:', y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6de8497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches -> train: 2 val: 2 | workers: 6 | batch_size: 512\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders (batch 512)\n",
    "num_workers = 6  # adjust based on CPU cores\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, persistent_workers=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=num_workers, persistent_workers=True)\n",
    "print('Batches -> train:', len(train_loader), 'val:', len(val_loader), '| workers:', num_workers, '| batch_size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbae1d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBeatsModule(\n",
      "  (stacks): ModuleList(\n",
      "    (0-2): 3 x ModuleList(\n",
      "      (0-2): 3 x NBeatsBlock(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=112, out_features=768, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.05, inplace=False)\n",
      "          (3): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.05, inplace=False)\n",
      "          (6): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.05, inplace=False)\n",
      "          (9): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (backcast_head): Linear(in_features=768, out_features=112, bias=True)\n",
      "        (forecast_head): Linear(in_features=768, out_features=30, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_fn): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "cfg_model = NBeatsConfig(input_length=INPUT_LENGTH, forecast_length=FORECAST_LENGTH, learning_rate=LEARNING_RATE, num_stacks=NUM_STACKS, num_blocks_per_stack=BLOCKS_PER_STACK, layer_width=LAYER_WIDTH, n_layers=N_LAYERS, dropout=DROPOUT)\n",
    "model = NBeatsModule(cfg_model).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d292d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully with torch.compile (mode=reduce-overhead).\n"
     ]
    }
   ],
   "source": [
    "# Optional experimental torch.compile step (PyTorch 2.x)\n",
    "import torch\n",
    "\n",
    "if hasattr(torch, 'compile'):\n",
    "    compile_mode = 'reduce-overhead'  # alternatives: 'max-autotune', 'default'\n",
    "    try:\n",
    "        # For MPS backend, fullgraph=False tends to be safer; dynamic shapes may break some passes.\n",
    "        model = torch.compile(model, mode=compile_mode, fullgraph=False)\n",
    "        print(f'Model compiled successfully with torch.compile (mode={compile_mode}).')\n",
    "    except Exception as e:\n",
    "        print('torch.compile failed:', type(e).__name__, str(e)[:300])\n",
    "        print('Falling back to original (uncompiled) model.')\n",
    "else:\n",
    "    print('torch.compile not available in this PyTorch build.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c8941fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 17,709,822 | Trainable: 17,709,822 (~17.710M)\n",
      "Avg forward time (compiled, batch=512): 2.94 ms | Throughput items*horizon/sec: 5231949.5\n",
      "Device: mps | Accelerator: mps\n",
      "Avg forward time (compiled, batch=512): 2.94 ms | Throughput items*horizon/sec: 5231949.5\n",
      "Device: mps | Accelerator: mps\n"
     ]
    }
   ],
   "source": [
    "# Parameter count & quick inference timing benchmark (post torch.compile, batch=512)\n",
    "import time, inspect\n",
    "\n",
    "if not hasattr(model, 'parameters') or inspect.isfunction(model):\n",
    "    print('Model reference invalid; recreating model instance...')\n",
    "    model = NBeatsModule(cfg_model).to(device)\n",
    "    if hasattr(torch, 'compile'):\n",
    "        try:\n",
    "            model = torch.compile(model, mode='reduce-overhead', fullgraph=False)\n",
    "            print('Recompiled new model instance.')\n",
    "        except Exception as e:\n",
    "            print('Recompile failed:', type(e).__name__, str(e)[:200])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total params: {total_params:,} | Trainable: {trainable_params:,} (~{trainable_params/1e6:.3f}M)\")\n",
    "\n",
    "try:\n",
    "    first_batch = next(iter(train_loader))[0]\n",
    "except StopIteration:\n",
    "    first_batch = torch.zeros((BATCH_SIZE, INPUT_LENGTH), dtype=torch.float32)\n",
    "xb = first_batch.to(device)\n",
    "\n",
    "for _ in range(3):\n",
    "    _ = model(xb)\n",
    "\n",
    "n_runs = 5\n",
    "start = time.perf_counter()\n",
    "for _ in range(n_runs):\n",
    "    _ = model(xb)\n",
    "end = time.perf_counter()\n",
    "\n",
    "avg_ms = (end - start) / n_runs * 1000\n",
    "throughput = (xb.shape[0] * FORECAST_LENGTH) / ((end - start) / n_runs)\n",
    "print(f\"Avg forward time (compiled, batch=512): {avg_ms:.2f} ms | Throughput items*horizon/sec: {throughput:.1f}\")\n",
    "print(f\"Device: {device} | Accelerator: {accelerator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Metric Interpretation & Overfitting Guide (updated for scaled run)\n",
    "# Refer to earlier explanations. After scaling model, monitor:\n",
    "#  - train_loss vs val_loss divergence\n",
    "#  - val_wape flattening\n",
    "#  - potential instability if precision < 32 on MPS\n",
    "# If OOM occurs, reduce BATCH_SIZE first, then LAYER_WIDTH.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/zak/Repos/E-commerce-Demand-Forecasting/notebooks/artifacts/models exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params | Mode\n",
      "----------------------------------------------\n",
      "0 | stacks  | ModuleList | 17.7 M | eval\n",
      "1 | loss_fn | MSELoss    | 0      | eval\n",
      "----------------------------------------------\n",
      "17.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 M    Total params\n",
      "70.839    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "149       Modules in eval mode\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/zak/Repos/E-commerce-Demand-Forecasting/notebooks/artifacts/models exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params | Mode\n",
      "----------------------------------------------\n",
      "0 | stacks  | ModuleList | 17.7 M | eval\n",
      "1 | loss_fn | MSELoss    | 0      | eval\n",
      "----------------------------------------------\n",
      "17.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 M    Total params\n",
      "70.839    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "149       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Adaptive Training Start ===\n",
      "Current device: mps | accelerator: mps\n",
      "Model is already uncompiled.\n",
      "Set TORCH_DISABLE_TORCHDYNAMO=1 for this training run (MPS backend).\n",
      "\n",
      "--- Attempting training with batch_size=256 ---\n",
      "Running sanity check + fit...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afa563f728b494f836d1ae59883f9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 150 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 150 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c61e2bb7988417eb9e77d48a39aba9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1104 14:01:58.730000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] torch._dynamo hit config.recompile_limit (8)\n",
      "W1104 14:01:58.730000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8]    function: 'log' (/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/core/module.py:384)\n",
      "W1104 14:01:58.730000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8]    last reason: 4/7: name == 'train_mae'                                    \n",
      "W1104 14:01:58.730000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1104 14:01:58.730000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "C1104 14:02:01.815000 79198 site-packages/torch/_inductor/scheduler.py:1198] [8/1_1] Error in codegen for ComputedBuffer(name='buf55', layout=FixedLayout('mps:0', torch.float32, size=[s71, 30], stride=[30, 1]), data=Pointwise(device=device(type='mps', index=0), dtype=torch.float32, inner_fn=<function make_pointwise.<locals>.inner.<locals>.inner_fn at 0x39bb10f40>, ranges=[s71, 30]))\n",
      "C1104 14:02:01.815000 79198 site-packages/torch/_inductor/scheduler.py:1198] [8/1_1] Error in codegen for ComputedBuffer(name='buf55', layout=FixedLayout('mps:0', torch.float32, size=[s71, 30], stride=[30, 1]), data=Pointwise(device=device(type='mps', index=0), dtype=torch.float32, inner_fn=<function make_pointwise.<locals>.inner.<locals>.inner_fn at 0x39bb10f40>, ranges=[s71, 30]))\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/zak/Repos/E-commerce-Demand-Forecasting/notebooks/artifacts/models exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params | Mode\n",
      "----------------------------------------------\n",
      "0 | stacks  | ModuleList | 17.7 M | eval\n",
      "1 | loss_fn | MSELoss    | 0      | eval\n",
      "----------------------------------------------\n",
      "17.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 M    Total params\n",
      "70.839    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "149       Modules in eval mode\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/zak/Repos/E-commerce-Demand-Forecasting/notebooks/artifacts/models exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params | Mode\n",
      "----------------------------------------------\n",
      "0 | stacks  | ModuleList | 17.7 M | eval\n",
      "1 | loss_fn | MSELoss    | 0      | eval\n",
      "----------------------------------------------\n",
      "17.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 M    Total params\n",
      "70.839    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "149       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 256 failed: InductorError: TypeError: cannot determine truth value of Relational: 30*s71 <= 1024\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer cont\n",
      "\n",
      "--- Attempting training with batch_size=128 ---\n",
      "Running sanity check + fit...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ed90050d584cb38ea71808ae003d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 150 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 150 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b0bebababc4f5f830b8993971b562b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1104 14:02:16.790000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] torch._dynamo hit config.recompile_limit (8)\n",
      "W1104 14:02:16.790000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8]    function: 'log' (/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/core/module.py:384)\n",
      "W1104 14:02:16.790000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8]    last reason: 4/7: name == 'train_mae'                                    \n",
      "W1104 14:02:16.790000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1104 14:02:16.790000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "C1104 14:02:19.984000 79198 site-packages/torch/_inductor/scheduler.py:1198] [8/1_1] Error in codegen for ComputedBuffer(name='buf55', layout=FixedLayout('mps:0', torch.float32, size=[s71, 30], stride=[30, 1]), data=Pointwise(device=device(type='mps', index=0), dtype=torch.float32, inner_fn=<function make_pointwise.<locals>.inner.<locals>.inner_fn at 0x331182480>, ranges=[s71, 30]))\n",
      "C1104 14:02:19.984000 79198 site-packages/torch/_inductor/scheduler.py:1198] [8/1_1] Error in codegen for ComputedBuffer(name='buf55', layout=FixedLayout('mps:0', torch.float32, size=[s71, 30], stride=[30, 1]), data=Pointwise(device=device(type='mps', index=0), dtype=torch.float32, inner_fn=<function make_pointwise.<locals>.inner.<locals>.inner_fn at 0x331182480>, ranges=[s71, 30]))\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/zak/Repos/E-commerce-Demand-Forecasting/notebooks/artifacts/models exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params | Mode\n",
      "----------------------------------------------\n",
      "0 | stacks  | ModuleList | 17.7 M | eval\n",
      "1 | loss_fn | MSELoss    | 0      | eval\n",
      "----------------------------------------------\n",
      "17.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 M    Total params\n",
      "70.839    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "149       Modules in eval mode\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /Users/zak/Repos/E-commerce-Demand-Forecasting/notebooks/artifacts/models exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params | Mode\n",
      "----------------------------------------------\n",
      "0 | stacks  | ModuleList | 17.7 M | eval\n",
      "1 | loss_fn | MSELoss    | 0      | eval\n",
      "----------------------------------------------\n",
      "17.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.7 M    Total params\n",
      "70.839    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "149       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 128 failed: InductorError: TypeError: cannot determine truth value of Relational: 30*s71 <= 1024\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer cont\n",
      "\n",
      "--- Attempting training with batch_size=64 ---\n",
      "Running sanity check + fit...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999f096468f24fb3b6c9a5031a96c69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 150 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n",
      "/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:527: Found 150 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acaea03fd5d4324ad814d623d23dd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1104 14:02:35.931000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] torch._dynamo hit config.recompile_limit (8)\n",
      "W1104 14:02:35.931000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8]    function: 'log' (/Users/zak/anaconda3/envs/DataCamp/lib/python3.11/site-packages/pytorch_lightning/core/module.py:384)\n",
      "W1104 14:02:35.931000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8]    last reason: 4/7: name == 'train_mae'                                    \n",
      "W1104 14:02:35.931000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1104 14:02:35.931000 79198 site-packages/torch/_dynamo/convert_frame.py:1016] [4/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "C1104 14:02:38.626000 79198 site-packages/torch/_inductor/scheduler.py:1198] [8/1_1] Error in codegen for ComputedBuffer(name='buf55', layout=FixedLayout('mps:0', torch.float32, size=[s71, 30], stride=[30, 1]), data=Pointwise(device=device(type='mps', index=0), dtype=torch.float32, inner_fn=<function make_pointwise.<locals>.inner.<locals>.inner_fn at 0x3433cff60>, ranges=[s71, 30]))\n",
      "C1104 14:02:38.626000 79198 site-packages/torch/_inductor/scheduler.py:1198] [8/1_1] Error in codegen for ComputedBuffer(name='buf55', layout=FixedLayout('mps:0', torch.float32, size=[s71, 30], stride=[30, 1]), data=Pointwise(device=device(type='mps', index=0), dtype=torch.float32, inner_fn=<function make_pointwise.<locals>.inner.<locals>.inner_fn at 0x3433cff60>, ranges=[s71, 30]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64 failed: InductorError: TypeError: cannot determine truth value of Relational: 30*s71 <= 1024\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer cont\n",
      "\n",
      "All attempts failed. Consider:\n",
      "- Reducing model width/blocks\n",
      "- Removing dropout\n",
      "- Switching off MPS (force CPU)\n",
      "- Upgrading PyTorch (Inductor fixes)\n",
      "=== Adaptive Training End ===\n"
     ]
    }
   ],
   "source": [
    "# Adaptive training cell v2: add CPU fallback if all MPS attempts fail; ensure model in train mode.\n",
    "import os, torch, pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torch._dynamo import reset as dynamo_reset\n",
    "\n",
    "print('\\n=== Adaptive Training Start (v2) ===')\n",
    "print(f'Current device: {device} | accelerator: {accelerator}')\n",
    "\n",
    "# Restore original model if compiled\n",
    "if hasattr(model, '_orig_mod'):\n",
    "    print('Restoring original (uncompiled) model from compiled wrapper.')\n",
    "    model = model._orig_mod\n",
    "else:\n",
    "    print('Model is already uncompiled.')\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Try to suppress dynamo entirely\n",
    "os.environ['TORCH_DISABLE_TORCHDYNAMO'] = '1'\n",
    "print('Set TORCH_DISABLE_TORCHDYNAMO=1 for this training scope.')\n",
    "\n",
    "attempt_batches = []\n",
    "if BATCH_SIZE not in (512, 256, 128, 64, 32):\n",
    "    attempt_batches.append(BATCH_SIZE)\n",
    "attempt_batches.extend([BATCH_SIZE, 256, 128, 64, 32])\n",
    "seen = set(); ordered_batches = []\n",
    "for b in attempt_batches:\n",
    "    if b not in seen and b > 0:\n",
    "        seen.add(b); ordered_batches.append(b)\n",
    "\n",
    "successful_batch = None\n",
    "last_error = None\n",
    "\n",
    "for bs in ordered_batches:\n",
    "    print(f'\\n--- Attempting MPS training with batch_size={bs} ---')\n",
    "    dynamo_reset()\n",
    "    try:\n",
    "        train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=num_workers, persistent_workers=(num_workers>0))\n",
    "        val_loader = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=num_workers)\n",
    "        # Recreate trainer with original kwargs\n",
    "        trainer = pl.Trainer(**trainer_kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        successful_batch = bs\n",
    "        print(f'MPS training succeeded with batch_size={bs}')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        err_type = type(e).__name__\n",
    "        msg = str(e)[:200]\n",
    "        print(f'MPS batch {bs} failed: {err_type}: {msg}')\n",
    "        last_error = e\n",
    "        continue\n",
    "\n",
    "if successful_batch is None and device.type == 'mps':\n",
    "    print('\\n>>> All MPS attempts failed; switching to CPU fallback.')\n",
    "    cpu_batch = 64 if 64 in ordered_batches else ordered_batches[-1]\n",
    "    cpu_device = torch.device('cpu')\n",
    "    model.to(cpu_device)\n",
    "    cpu_train_loader = DataLoader(train_ds, batch_size=cpu_batch, shuffle=True, num_workers=0)\n",
    "    cpu_val_loader = DataLoader(val_ds, batch_size=cpu_batch, shuffle=False, num_workers=0)\n",
    "    cpu_trainer_kwargs = dict(trainer_kwargs)\n",
    "    cpu_trainer_kwargs['accelerator'] = 'cpu'\n",
    "    cpu_trainer_kwargs['devices'] = 1\n",
    "    print(f'CPU fallback: batch_size={cpu_batch}')\n",
    "    try:\n",
    "        trainer = pl.Trainer(**cpu_trainer_kwargs)\n",
    "        trainer.fit(model, cpu_train_loader, cpu_val_loader)\n",
    "        successful_batch = cpu_batch\n",
    "        print('CPU training succeeded.')\n",
    "        device = cpu_device  # update global\n",
    "    except Exception as e:\n",
    "        print('CPU fallback failed:', type(e).__name__, str(e)[:200])\n",
    "\n",
    "if successful_batch is None:\n",
    "    print('\\nTraining failed on all backends. Suggestions:')\n",
    "    print('- Reduce LAYER_WIDTH (e.g., 512)')\n",
    "    print('- Reduce BLOCKS_PER_STACK or NUM_STACKS')\n",
    "    print('- Upgrade PyTorch (nightly) for MPS Inductor fixes')\n",
    "    print('- Use CPU for now and rely on smaller model')\n",
    "else:\n",
    "    BATCH_SIZE = successful_batch\n",
    "    print(f'\\nEffective batch size used: {BATCH_SIZE} | Final device: {device}')\n",
    "\n",
    "print('=== Adaptive Training End (v2) ===')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c290fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 2.2445 | MAE: 1.1766 | WAPE: 7.38%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set (manual pass) with explicit device move\n",
    "model.eval()\n",
    "model.to(device)\n",
    "val_losses = []\n",
    "val_mae = []\n",
    "val_wape_num = 0.0\n",
    "val_wape_den = 0.0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        pred = model(xb)\n",
    "        loss = torch.mean((pred - yb)**2)\n",
    "        mae = torch.mean(torch.abs(pred - yb))\n",
    "        val_losses.append(loss.item())\n",
    "        val_mae.append(mae.item())\n",
    "        val_wape_num += torch.sum(torch.abs(pred - yb)).item()\n",
    "        val_wape_den += torch.sum(torch.abs(yb)).item()\n",
    "avg_loss = sum(val_losses)/len(val_losses)\n",
    "avg_mae = sum(val_mae)/len(val_mae)\n",
    "wape = math.nan if val_wape_den == 0 else 100.0 * val_wape_num/val_wape_den\n",
    "print(f'Validation MSE: {avg_loss:.4f} | MAE: {avg_mae:.4f} | WAPE: {wape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3e496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint -> artifacts/models/nbeats_notebook.ckpt\n",
      "Saved metrics -> artifacts/models/nbeats_notebook_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save artifacts\n",
    "CKPT_PATH = ARTIFACTS_DIR / 'nbeats_notebook.ckpt'\n",
    "torch.save(model.state_dict(), CKPT_PATH)\n",
    "metrics = {\n",
    "    'validation_mse': avg_loss,\n",
    "    'validation_mae': avg_mae,\n",
    "    'validation_wape': wape,\n",
    "    'config': cfg_model.__dict__,\n",
    "    'n_train_windows': len(train_ds),\n",
    "    'n_val_windows': len(val_ds),\n",
    "}\n",
    "with open(ARTIFACTS_DIR / 'nbeats_notebook_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print('Saved checkpoint ->', CKPT_PATH)\n",
    "print('Saved metrics ->', ARTIFACTS_DIR / 'nbeats_notebook_metrics.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc149ce9",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Integrate with backtesting harness.\n",
    "- Add basis (trend/seasonality) blocks for improved decomposition.\n",
    "- Introduce quantile heads for probabilistic forecasts.\n",
    "- Add per-item embeddings & categorical covariates.\n",
    "- Promote best checkpoint to API service for live forecasts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
